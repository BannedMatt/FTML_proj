{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c70aa77",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "Same instructions as in 4, except that this time a classification has to\n",
    "be performed and the data and the dataset is stored in FTML/Project/data/classification/.\n",
    "Your objective should be to obtain a mean accuracy superior to 0.85 on the test set\n",
    "(same remark about the test set).\n",
    "Indication : a solution, with the correct hyperparameters, exists in scikit among\n",
    "the following scikit classes :\n",
    "- linear_model.LogisticRegression\n",
    "- svm.SVC\n",
    "- neighbors.KNeighborsClassifier\n",
    "- neural_network.MLPClassifier\n",
    "- ensemble.AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61556080",
   "metadata": {},
   "source": [
    "We firstly define the librairies we will use, load the data, print some information on it and finally define our target accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55a6438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: X_train (2000, 30), y_train (2000,)\n",
      "test set shape: X_test (2000, 30), y_test (2000,)\n",
      "unique classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "X_train = np.load(\"../data/classification/X_train.npy\")\n",
    "y_train = np.load(\"../data/classification/y_train.npy\")\n",
    "X_test = np.load(\"../data/classification/X_test.npy\")\n",
    "y_test = np.load(\"../data/classification/y_test.npy\")\n",
    "\n",
    "print(f\"dataset shape: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"test set shape: X_test {X_test.shape}, y_test {y_test.shape}\")\n",
    "print(f\"unique classes: {np.unique(y_train)}\")\n",
    "\n",
    "TARGET_ACCURACY = 0.85 # as written in the subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a9e9a",
   "metadata": {},
   "source": [
    "## Model that we will be using\n",
    "\n",
    "we define the different models that we will test. Our objective is classification so we use classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "392cba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'MLP Classifier': MLPClassifier(random_state=42, max_iter=2000),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "cv_results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1049f5",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning\n",
    "\n",
    "we will use optuma to do our hyperparameter tuning. We will do 100 trials for each models. To see how our model is performing we will first test it on the train data, doing cross validation (CV), this will say how we should do the hyperparameter tuning, rejecting parameters that give worse mean accuracy while CV. We will then, when all the models are trained test them on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be18231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:13:43,645] A new study created in memory with name: LogisticRegression_optimization\n",
      "[I 2025-07-05 02:13:43,722] Trial 0 finished with value: 0.7154999999999999 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.2914552612272273}. Best is trial 0 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:13:43,766] Trial 1 finished with value: 0.7200000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.010532256457261163}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:43,791] Trial 2 finished with value: 0.7155 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.045741220666837674}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:43,970] Trial 3 finished with value: 0.712 and parameters: {'penalty': 'elasticnet', 'solver': 'liblinear', 'C': 0.11224410523774374, 'l1_ratio': 0.15402281101340576}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,000] Trial 4 finished with value: 0.715 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.007505256635934552}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,046] Trial 5 finished with value: 0.7190000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.033278865947238966}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,092] Trial 6 finished with value: 0.716 and parameters: {'penalty': 'elasticnet', 'solver': 'liblinear', 'C': 0.038962104620653956, 'l1_ratio': 0.7728512329094901}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,346] Trial 7 finished with value: 0.713 and parameters: {'penalty': 'elasticnet', 'solver': 'saga', 'C': 0.17212934115970158, 'l1_ratio': 0.16665630161408285}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,382] Trial 8 finished with value: 0.714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.16093390953837036}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,426] Trial 9 finished with value: 0.719 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0854065528305397}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,564] Trial 10 finished with value: 0.7144999999999999 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 7.738359083992167}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:44,583] Trial 11 finished with value: 0.5095 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0010063615405230875}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,262] Trial 12 finished with value: 0.714 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 3.889585882957833}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,317] Trial 13 finished with value: 0.6875 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.004112907512522383}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,589] Trial 14 finished with value: 0.7144999999999999 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 55.87099957682767}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,633] Trial 15 finished with value: 0.7144999999999999 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.01026720331546783}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,801] Trial 16 finished with value: 0.7125 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.8221356523206856}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,832] Trial 17 finished with value: 0.5095 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0011539132886078127}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:45,857] Trial 18 finished with value: 0.714 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0230108393165771}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:46,031] Trial 19 finished with value: 0.7135 and parameters: {'penalty': 'elasticnet', 'solver': 'saga', 'C': 0.5983984382978595, 'l1_ratio': 0.8334224857743155}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:46,078] Trial 20 finished with value: 0.6744999999999999 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0035394111257998438}. Best is trial 1 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:13:46,121] Trial 21 finished with value: 0.7215 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.01870528099598676}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,171] Trial 22 finished with value: 0.72 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.016240472919257565}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,222] Trial 23 finished with value: 0.7175 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.013370321239734577}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,268] Trial 24 finished with value: 0.6715000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.00259008103315217}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,312] Trial 25 finished with value: 0.719 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.014540664459091718}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,328] Trial 26 finished with value: 0.7074999999999999 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.005817609522865407}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,382] Trial 27 finished with value: 0.7155000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.05419278899698805}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,421] Trial 28 finished with value: 0.714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.002064260027355669}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,664] Trial 29 finished with value: 0.7135 and parameters: {'penalty': 'elasticnet', 'solver': 'saga', 'C': 0.3923266827573785, 'l1_ratio': 0.4779657188737589}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,883] Trial 30 finished with value: 0.7135 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 1.2107698154547135}. Best is trial 21 with value: 0.7215.\n",
      "[I 2025-07-05 02:13:46,937] Trial 31 finished with value: 0.7225 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0231517340570911}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:46,984] Trial 32 finished with value: 0.7225 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02207133447058767}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,032] Trial 33 finished with value: 0.719 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.08884541515451541}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,048] Trial 34 finished with value: 0.7104999999999999 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.006672709644211873}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,092] Trial 35 finished with value: 0.7205 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02816432923478675}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,152] Trial 36 finished with value: 0.7210000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02527973110524183}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,212] Trial 37 finished with value: 0.7155000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.05297482018089956}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,362] Trial 38 finished with value: 0.714 and parameters: {'penalty': 'elasticnet', 'solver': 'liblinear', 'C': 0.23986869431769342, 'l1_ratio': 0.49175458046573506}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,398] Trial 39 finished with value: 0.7210000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.024250628251947123}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,428] Trial 40 finished with value: 0.714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.0821776703564424}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,463] Trial 41 finished with value: 0.7225 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.021632494082285927}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,499] Trial 42 finished with value: 0.7185 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.009232740802016517}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,538] Trial 43 finished with value: 0.716 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.03863789219880819}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,581] Trial 44 finished with value: 0.716 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.12876583879938336}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,616] Trial 45 finished with value: 0.7210000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.018375502256780828}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,659] Trial 46 finished with value: 0.7185 and parameters: {'penalty': 'elasticnet', 'solver': 'saga', 'C': 0.06617388447270794, 'l1_ratio': 0.639420621633512}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,675] Trial 47 finished with value: 0.714 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.031766838641746224}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,710] Trial 48 finished with value: 0.708 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.005525171619232868}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,752] Trial 49 finished with value: 0.7144999999999999 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 96.4956199778407}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,786] Trial 50 finished with value: 0.714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.18916487099422832}. Best is trial 31 with value: 0.7225.\n",
      "[I 2025-07-05 02:13:47,829] Trial 51 finished with value: 0.7230000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0212809980245425}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:47,872] Trial 52 finished with value: 0.7200000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.011845144123715677}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:47,920] Trial 53 finished with value: 0.716 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.046687101075964174}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:47,965] Trial 54 finished with value: 0.7185 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.008708244157588148}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,009] Trial 55 finished with value: 0.722 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.020042728828831704}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,064] Trial 56 finished with value: 0.717 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.11965599469839781}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,111] Trial 57 finished with value: 0.655 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0018594981597440745}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,172] Trial 58 finished with value: 0.7175 and parameters: {'penalty': 'elasticnet', 'solver': 'liblinear', 'C': 0.01831061916375419, 'l1_ratio': 0.3394538621672534}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,224] Trial 59 finished with value: 0.6855 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.004063931850081396}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,282] Trial 60 finished with value: 0.7165 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.037092164471393345}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,331] Trial 61 finished with value: 0.7210000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.024014160381426827}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,380] Trial 62 finished with value: 0.718 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.012497586247560153}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,430] Trial 63 finished with value: 0.7205 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.018186745098371707}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,476] Trial 64 finished with value: 0.7015 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.00522630810687792}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,522] Trial 65 finished with value: 0.7144999999999999 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 18.062635123404966}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,574] Trial 66 finished with value: 0.7175 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.00847815291240623}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,622] Trial 67 finished with value: 0.72 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02939327985625496}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,675] Trial 68 finished with value: 0.718 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.06213167630602182}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,692] Trial 69 finished with value: 0.6765 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.0034951501400280797}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,746] Trial 70 finished with value: 0.718 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.013487899459069648}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,801] Trial 71 finished with value: 0.7210000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.018321903170307626}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,853] Trial 72 finished with value: 0.7205 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.024502380550078553}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,905] Trial 73 finished with value: 0.716 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.04050435058743853}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:48,954] Trial 74 finished with value: 0.7210000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02403119119241897}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,089] Trial 75 finished with value: 0.715 and parameters: {'penalty': 'elasticnet', 'solver': 'saga', 'C': 0.06936494834370212, 'l1_ratio': 0.3514817534816209}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,146] Trial 76 finished with value: 0.7185 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.09440818419950216}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,192] Trial 77 finished with value: 0.7175 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.007257128570790143}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,238] Trial 78 finished with value: 0.7144999999999999 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.010363011653440122}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,292] Trial 79 finished with value: 0.7150000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.05015080564283698}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,429] Trial 80 finished with value: 0.7135 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 2.171695206697928}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,480] Trial 81 finished with value: 0.7205 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.017381653365710358}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,537] Trial 82 finished with value: 0.718 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.03568718848980816}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,591] Trial 83 finished with value: 0.7225 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.021728356285361433}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,643] Trial 84 finished with value: 0.7220000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02345540119078405}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,695] Trial 85 finished with value: 0.7175 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.013889131741225405}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,745] Trial 86 finished with value: 0.7205 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.030087981051613588}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,793] Trial 87 finished with value: 0.7200000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.010530110385154598}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,855] Trial 88 finished with value: 0.719 and parameters: {'penalty': 'elasticnet', 'solver': 'saga', 'C': 0.04636966206422177, 'l1_ratio': 0.6413352950809688}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:49,907] Trial 89 finished with value: 0.7174999999999999 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.006940992764752841}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,003] Trial 90 finished with value: 0.7135 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.38776990667065575}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,049] Trial 91 finished with value: 0.722 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02056282694877035}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,099] Trial 92 finished with value: 0.722 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.020676571655580567}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,151] Trial 93 finished with value: 0.7220000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.019482344306832447}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,202] Trial 94 finished with value: 0.719 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.015133307850563075}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,254] Trial 95 finished with value: 0.7230000000000001 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.02286752693318984}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,311] Trial 96 finished with value: 0.7175 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.035825004265228506}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,359] Trial 97 finished with value: 0.7015 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.005260474587025837}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,402] Trial 98 finished with value: 0.713 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.06661465781608678}. Best is trial 51 with value: 0.7230000000000001.\n",
      "[I 2025-07-05 02:13:50,423] Trial 99 finished with value: 0.7145 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.029423349202727888}. Best is trial 51 with value: 0.7230000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression params: {'penalty': 'l1', 'solver': 'saga', 'C': 0.0212809980245425}\n",
      "Best Logistic Regression cross-validation score: 0.7230\n"
     ]
    }
   ],
   "source": [
    "def optimize_logistic_regression(trial):\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "    \n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-3, 100, log=True),\n",
    "        'penalty': penalty,\n",
    "        'solver': solver,\n",
    "        'random_state': 42,\n",
    "        'max_iter': 2000\n",
    "    }\n",
    "    \n",
    "    if penalty == 'elasticnet':\n",
    "        params['solver'] = 'saga'\n",
    "        params['l1_ratio'] = trial.suggest_float('l1_ratio', 0.1, 0.9)\n",
    "    elif penalty == 'l1':\n",
    "        if solver not in ['liblinear', 'saga']:\n",
    "            params['solver'] = 'liblinear'\n",
    "    \n",
    "    model = LogisticRegression(**params) \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "lr_study = optuna.create_study(direction='maximize', study_name=\"LogisticRegression_optimization\")\n",
    "lr_study.optimize(optimize_logistic_regression, n_trials=100)\n",
    "\n",
    "print(f\"Best Logistic Regression params: {lr_study.best_params}\")\n",
    "print(f\"Best Logistic Regression cross-validation score: {lr_study.best_value:.4f}\")\n",
    "\n",
    "best_lr_params = lr_study.best_params.copy()\n",
    "\n",
    "if best_lr_params['penalty'] == 'elasticnet':\n",
    "    best_lr_params['solver'] = 'saga'\n",
    "    if 'l1_ratio' not in best_lr_params:\n",
    "        best_lr_params['l1_ratio'] = 0.5 \n",
    "elif best_lr_params['penalty'] == 'l1':\n",
    "    if best_lr_params['solver'] not in ['liblinear', 'saga']:\n",
    "        best_lr_params['solver'] = 'liblinear'\n",
    "\n",
    "best_lr_model = LogisticRegression(**best_lr_params)\n",
    "best_lr_model.fit(X_train, y_train)\n",
    "\n",
    "best_models['Logistic Regression'] = best_lr_model\n",
    "cv_results['Logistic Regression'] = lr_study.best_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136a1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:13:50,446] A new study created in memory with name: KNN_optimization\n",
      "[I 2025-07-05 02:13:50,557] Trial 0 finished with value: 0.762 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 0 with value: 0.762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing K-Nearest Neighbors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:13:50,659] Trial 1 finished with value: 0.76 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 0 with value: 0.762.\n",
      "[I 2025-07-05 02:13:50,766] Trial 2 finished with value: 0.769 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 2 with value: 0.769.\n",
      "[I 2025-07-05 02:13:50,874] Trial 3 finished with value: 0.7455 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 2 with value: 0.769.\n",
      "[I 2025-07-05 02:13:51,001] Trial 4 finished with value: 0.7779999999999999 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 4 with value: 0.7779999999999999.\n",
      "[I 2025-07-05 02:13:51,119] Trial 5 finished with value: 0.76 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 4 with value: 0.7779999999999999.\n",
      "[I 2025-07-05 02:13:51,233] Trial 6 finished with value: 0.7775 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 4 with value: 0.7779999999999999.\n",
      "[I 2025-07-05 02:13:51,344] Trial 7 finished with value: 0.7779999999999999 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 4 with value: 0.7779999999999999.\n",
      "[I 2025-07-05 02:13:51,445] Trial 8 finished with value: 0.7775 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 4 with value: 0.7779999999999999.\n",
      "[I 2025-07-05 02:13:51,556] Trial 9 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:51,674] Trial 10 finished with value: 0.7695000000000001 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:51,790] Trial 11 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:51,901] Trial 12 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,012] Trial 13 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,129] Trial 14 finished with value: 0.7714999999999999 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,242] Trial 15 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,358] Trial 16 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,467] Trial 17 finished with value: 0.776 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,578] Trial 18 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,695] Trial 19 finished with value: 0.7714999999999999 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,810] Trial 20 finished with value: 0.7775 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:52,933] Trial 21 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,047] Trial 22 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,159] Trial 23 finished with value: 0.7799999999999999 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,282] Trial 24 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,401] Trial 25 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,515] Trial 26 finished with value: 0.7799999999999999 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,630] Trial 27 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,745] Trial 28 finished with value: 0.765 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,860] Trial 29 finished with value: 0.7799999999999999 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:53,978] Trial 30 finished with value: 0.7675 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,089] Trial 31 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,202] Trial 32 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,320] Trial 33 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,436] Trial 34 finished with value: 0.77 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,542] Trial 35 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,653] Trial 36 finished with value: 0.774 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,763] Trial 37 finished with value: 0.769 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,879] Trial 38 finished with value: 0.782 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:54,992] Trial 39 finished with value: 0.7765 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,106] Trial 40 finished with value: 0.7775 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,223] Trial 41 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,341] Trial 42 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,455] Trial 43 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,566] Trial 44 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,678] Trial 45 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,792] Trial 46 finished with value: 0.7799999999999999 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,902] Trial 47 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:55,948] Trial 48 finished with value: 0.7665 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,057] Trial 49 finished with value: 0.7809999999999999 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,163] Trial 50 finished with value: 0.76 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,273] Trial 51 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,381] Trial 52 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,486] Trial 53 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,597] Trial 54 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,705] Trial 55 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,817] Trial 56 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:56,936] Trial 57 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,051] Trial 58 finished with value: 0.7775000000000001 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,159] Trial 59 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,269] Trial 60 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,380] Trial 61 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,490] Trial 62 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,600] Trial 63 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,712] Trial 64 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,823] Trial 65 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:57,928] Trial 66 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,039] Trial 67 finished with value: 0.7799999999999999 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,142] Trial 68 finished with value: 0.7779999999999999 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,256] Trial 69 finished with value: 0.7714999999999999 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,364] Trial 70 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,466] Trial 71 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,575] Trial 72 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,683] Trial 73 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,792] Trial 74 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:58,895] Trial 75 finished with value: 0.7775 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,006] Trial 76 finished with value: 0.782 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,114] Trial 77 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,221] Trial 78 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,332] Trial 79 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,438] Trial 80 finished with value: 0.7799999999999999 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,544] Trial 81 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,648] Trial 82 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,753] Trial 83 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,863] Trial 84 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:13:59,972] Trial 85 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,072] Trial 86 finished with value: 0.7765 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,177] Trial 87 finished with value: 0.7695000000000001 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,290] Trial 88 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,397] Trial 89 finished with value: 0.776 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,505] Trial 90 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,606] Trial 91 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,713] Trial 92 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,822] Trial 93 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:00,933] Trial 94 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:01,037] Trial 95 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:01,145] Trial 96 finished with value: 0.7825 and parameters: {'n_neighbors': 15, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:01,254] Trial 97 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:01,360] Trial 98 finished with value: 0.786 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 9 with value: 0.786.\n",
      "[I 2025-07-05 02:14:01,460] Trial 99 finished with value: 0.7805 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'minkowski'}. Best is trial 9 with value: 0.786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K-Nearest Neighbors params: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Best K-Nearest Neighbors cross-validation score: 0.7860\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def optimize_knn(trial):\n",
    "    params = {\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        'metric': trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "    }\n",
    "    \n",
    "    model = KNeighborsClassifier(**params) \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "knn_study = optuna.create_study(direction='maximize', study_name=\"KNN_optimization\")\n",
    "knn_study.optimize(optimize_knn, n_trials=100)\n",
    "\n",
    "print(f\"Best K-Nearest Neighbors params: {knn_study.best_params}\")\n",
    "print(f\"Best K-Nearest Neighbors cross-validation score: {knn_study.best_value:.4f}\")\n",
    "\n",
    "best_knn_params = knn_study.best_params\n",
    "best_knn_model = KNeighborsClassifier(**best_knn_params)\n",
    "best_knn_model.fit(X_train, y_train)\n",
    "\n",
    "best_models['K-Nearest Neighbors'] = best_knn_model\n",
    "cv_results['K-Nearest Neighbors'] = knn_study.best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2450518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:14:01,471] A new study created in memory with name: MLP_optimization\n",
      "[I 2025-07-05 02:14:08,333] Trial 0 finished with value: 0.749 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0010966731262273496, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:14:20,547] Trial 1 finished with value: 0.7195 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.01597521465885276, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:14:30,741] Trial 2 finished with value: 0.7165 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.007222985707526683, 'learning_rate': 'adaptive'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:14:42,585] Trial 3 finished with value: 0.7154999999999999 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.05174689363765446, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:14:47,364] Trial 4 finished with value: 0.7335 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.00013013512961296777, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:14:59,588] Trial 5 finished with value: 0.7225 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.008950679708332892, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:15:11,188] Trial 6 finished with value: 0.7205 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.02882360393913957, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:15:21,443] Trial 7 finished with value: 0.7059999999999998 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0001452303905631634, 'learning_rate': 'adaptive'}. Best is trial 0 with value: 0.749.\n",
      "[I 2025-07-05 02:15:28,065] Trial 8 finished with value: 0.7525000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.022145694168962164, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:15:34,651] Trial 9 finished with value: 0.7494999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0021800378830655613, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:15:42,177] Trial 10 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.06479028590102237, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:15:57,921] Trial 11 finished with value: 0.749 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.09379382439151834, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:14,343] Trial 12 finished with value: 0.7435 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.09874930927250275, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:20,886] Trial 13 finished with value: 0.7465 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.025129566660052383, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:26,041] Trial 14 finished with value: 0.7365 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.004893025993692154, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:32,536] Trial 15 finished with value: 0.7475 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0007570496804482603, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:39,193] Trial 16 finished with value: 0.7525000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03533275564558549, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:45,368] Trial 17 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.012979034609014565, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:16:56,025] Trial 18 finished with value: 0.708 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.03344701998937002, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:01,226] Trial 19 finished with value: 0.733 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.003158368252744749, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:07,337] Trial 20 finished with value: 0.7515000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.016986698567026105, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:14,199] Trial 21 finished with value: 0.75 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05085563871671328, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:20,993] Trial 22 finished with value: 0.7495 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.055186593482410416, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:28,164] Trial 23 finished with value: 0.7525 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03842232590029173, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:34,463] Trial 24 finished with value: 0.75 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.024629395086608604, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:41,224] Trial 25 finished with value: 0.751 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00847270621987701, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:47,811] Trial 26 finished with value: 0.7525000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03736976179965902, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:17:53,235] Trial 27 finished with value: 0.727 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.015173260206979388, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:03,744] Trial 28 finished with value: 0.7005 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00030622860488366634, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:10,006] Trial 29 finished with value: 0.748 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0014463066123563614, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:16,307] Trial 30 finished with value: 0.7485 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.004932496408216223, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:22,870] Trial 31 finished with value: 0.7515 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03654202740982521, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:29,031] Trial 32 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.021155176100130582, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:35,499] Trial 33 finished with value: 0.748 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.042753676806404725, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:47,277] Trial 34 finished with value: 0.7285 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.06980937601539096, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:18:53,511] Trial 35 finished with value: 0.7515 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.010318243218179418, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:19:02,825] Trial 36 finished with value: 0.712 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.019630572885842433, 'learning_rate': 'constant'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:19:14,002] Trial 37 finished with value: 0.7215 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.005933878894796791, 'learning_rate': 'adaptive'}. Best is trial 8 with value: 0.7525000000000001.\n",
      "[I 2025-07-05 02:19:20,412] Trial 38 finished with value: 0.7535000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0363574722993155, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:19:25,249] Trial 39 finished with value: 0.7325000000000002 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.013076398953256676, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:19:36,818] Trial 40 finished with value: 0.721 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.07646736234935997, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:19:43,120] Trial 41 finished with value: 0.748 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.039049891357537024, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:19:49,190] Trial 42 finished with value: 0.7510000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.027713503455937778, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:19:55,746] Trial 43 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.04814183431558703, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:01,828] Trial 44 finished with value: 0.753 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.02952112845297245, 'learning_rate': 'adaptive'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:09,595] Trial 45 finished with value: 0.748 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.07283823983892625, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:13,911] Trial 46 finished with value: 0.7529999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.01157041606511747, 'learning_rate': 'adaptive'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:18,411] Trial 47 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.010347065448750324, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:24,684] Trial 48 finished with value: 0.7095 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.01848073913164753, 'learning_rate': 'adaptive'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:29,657] Trial 49 finished with value: 0.7510000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.007242016236900325, 'learning_rate': 'constant'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:34,411] Trial 50 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.027136896649052996, 'learning_rate': 'adaptive'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:38,801] Trial 51 finished with value: 0.7474999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.028869833951000474, 'learning_rate': 'adaptive'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:42,869] Trial 52 finished with value: 0.751 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.013131862056292375, 'learning_rate': 'adaptive'}. Best is trial 38 with value: 0.7535000000000001.\n",
      "[I 2025-07-05 02:20:47,738] Trial 53 finished with value: 0.7545 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05856973412692063, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:20:52,873] Trial 54 finished with value: 0.747 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05780088598403649, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:20:56,846] Trial 55 finished with value: 0.735 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.09765399949451557, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:01,272] Trial 56 finished with value: 0.7449999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0033674973417003916, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:09,414] Trial 57 finished with value: 0.7220000000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.021451048800844145, 'learning_rate': 'constant'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:14,094] Trial 58 finished with value: 0.7494999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.02973455999803661, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:18,606] Trial 59 finished with value: 0.7475 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.049987777702745484, 'learning_rate': 'constant'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:24,398] Trial 60 finished with value: 0.7165 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.015450249520079217, 'learning_rate': 'constant'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:28,419] Trial 61 finished with value: 0.75 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03657884868842924, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:32,989] Trial 62 finished with value: 0.746 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.060505896460002914, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:37,019] Trial 63 finished with value: 0.7529999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.02319339789518572, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:40,823] Trial 64 finished with value: 0.7515 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0221356904416502, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:44,849] Trial 65 finished with value: 0.749 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.032500418569416135, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:48,692] Trial 66 finished with value: 0.75 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.010685806356718622, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:55,737] Trial 67 finished with value: 0.7464999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.08342960485515706, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:21:58,790] Trial 68 finished with value: 0.735 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.0005593473686699196, 'learning_rate': 'constant'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:22:02,807] Trial 69 finished with value: 0.751 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.016851359223560507, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:22:08,133] Trial 70 finished with value: 0.752 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.045531390545244604, 'learning_rate': 'constant'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:22:12,402] Trial 71 finished with value: 0.7510000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.02449039879659106, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:22:16,511] Trial 72 finished with value: 0.7545 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.034812415409875286, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:22:20,816] Trial 73 finished with value: 0.7499999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.043012099715545773, 'learning_rate': 'adaptive'}. Best is trial 53 with value: 0.7545.\n",
      "[I 2025-07-05 02:22:25,983] Trial 74 finished with value: 0.7565 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05938953197404983, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:22:30,526] Trial 75 finished with value: 0.7499999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05788944840923385, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:22:37,995] Trial 76 finished with value: 0.7545 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0831928527837834, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:22:43,580] Trial 77 finished with value: 0.7515000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.06926809918666177, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:22:51,410] Trial 78 finished with value: 0.73 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.08397217247812294, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:01,893] Trial 79 finished with value: 0.7444999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.09894110114484019, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:07,516] Trial 80 finished with value: 0.7180000000000001 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0517010624064904, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:12,079] Trial 81 finished with value: 0.7525 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03075949165638754, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:16,366] Trial 82 finished with value: 0.7535000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.04114701345440302, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:21,291] Trial 83 finished with value: 0.7459999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0655809267202926, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:25,401] Trial 84 finished with value: 0.7455 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.042760473204613125, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:29,402] Trial 85 finished with value: 0.755 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03523075451482107, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:35,598] Trial 86 finished with value: 0.7460000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.07942561403062251, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:39,448] Trial 87 finished with value: 0.7485 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0356339888954042, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:42,656] Trial 88 finished with value: 0.7344999999999999 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.05632070411491868, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:46,658] Trial 89 finished with value: 0.7545 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.046084925792053734, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:50,541] Trial 90 finished with value: 0.7510000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.04408895726232253, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:55,181] Trial 91 finished with value: 0.7499999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.06484045454287614, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:23:59,267] Trial 92 finished with value: 0.7505 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05051944573882314, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:03,145] Trial 93 finished with value: 0.7515 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0345620557173587, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:10,436] Trial 94 finished with value: 0.7464999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.08360404015019941, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:14,260] Trial 95 finished with value: 0.7545 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.03996746171094228, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:18,065] Trial 96 finished with value: 0.75 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.026848684758739288, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:25,093] Trial 97 finished with value: 0.7220000000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.03853283020094015, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:29,591] Trial 98 finished with value: 0.7495 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.06395429129492289, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n",
      "[I 2025-07-05 02:24:33,321] Trial 99 finished with value: 0.75 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00015627958924340128, 'learning_rate': 'adaptive'}. Best is trial 74 with value: 0.7565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Classifier params: {'hidden_layer_sizes': (100, 50), 'alpha': 0.05938953197404983, 'learning_rate': 'adaptive'}\n",
      "Best MLP Classifier cross-validation score: 0.7565\n"
     ]
    }
   ],
   "source": [
    "def optimize_mlp(trial):\n",
    "    params = {\n",
    "        'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50)]),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-4, 1e-1, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', ['constant', 'adaptive']),\n",
    "        'random_state': 42,\n",
    "        'max_iter': 2000\n",
    "    }\n",
    "    \n",
    "    model = MLPClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "mlp_study = optuna.create_study(direction='maximize', study_name=\"MLP_optimization\")\n",
    "mlp_study.optimize(optimize_mlp, n_trials=100)\n",
    "\n",
    "print(f\"Best MLP Classifier params: {mlp_study.best_params}\")\n",
    "print(f\"Best MLP Classifier cross-validation score: {mlp_study.best_value:.4f}\")\n",
    "\n",
    "best_mlp_params = mlp_study.best_params\n",
    "best_mlp_model = MLPClassifier(**best_mlp_params)\n",
    "best_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "best_models['MLP Classifier'] = best_mlp_model\n",
    "cv_results['MLP Classifier'] = mlp_study.best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aca1858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:24:34,355] A new study created in memory with name: AdaBoost_optimization\n",
      "[I 2025-07-05 02:24:37,195] Trial 0 finished with value: 0.701 and parameters: {'n_estimators': 130, 'learning_rate': 0.6279749248412576}. Best is trial 0 with value: 0.701.\n",
      "[I 2025-07-05 02:24:40,190] Trial 1 finished with value: 0.7115 and parameters: {'n_estimators': 137, 'learning_rate': 0.4705483456215528}. Best is trial 1 with value: 0.7115.\n",
      "[I 2025-07-05 02:24:43,903] Trial 2 finished with value: 0.7154999999999999 and parameters: {'n_estimators': 170, 'learning_rate': 0.31031814178700123}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:24:47,675] Trial 3 finished with value: 0.7034999999999999 and parameters: {'n_estimators': 171, 'learning_rate': 0.5187507064501229}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:24:49,055] Trial 4 finished with value: 0.71 and parameters: {'n_estimators': 63, 'learning_rate': 0.555894496824633}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:24:50,925] Trial 5 finished with value: 0.6975 and parameters: {'n_estimators': 82, 'learning_rate': 0.7012223177435022}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:24:54,247] Trial 6 finished with value: 0.709 and parameters: {'n_estimators': 145, 'learning_rate': 0.12025560658240916}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:24:57,436] Trial 7 finished with value: 0.704 and parameters: {'n_estimators': 143, 'learning_rate': 0.0641819868375637}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:25:00,466] Trial 8 finished with value: 0.7 and parameters: {'n_estimators': 139, 'learning_rate': 0.8128770620621497}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:25:02,215] Trial 9 finished with value: 0.708 and parameters: {'n_estimators': 80, 'learning_rate': 0.14626229034905874}. Best is trial 2 with value: 0.7154999999999999.\n",
      "[I 2025-07-05 02:25:06,360] Trial 10 finished with value: 0.7155000000000001 and parameters: {'n_estimators': 189, 'learning_rate': 0.326758049860718}. Best is trial 10 with value: 0.7155000000000001.\n",
      "[I 2025-07-05 02:25:10,706] Trial 11 finished with value: 0.7150000000000001 and parameters: {'n_estimators': 199, 'learning_rate': 0.32747179751436023}. Best is trial 10 with value: 0.7155000000000001.\n",
      "[I 2025-07-05 02:25:15,091] Trial 12 finished with value: 0.715 and parameters: {'n_estimators': 200, 'learning_rate': 0.30353411097095573}. Best is trial 10 with value: 0.7155000000000001.\n",
      "[I 2025-07-05 02:25:18,905] Trial 13 finished with value: 0.7144999999999999 and parameters: {'n_estimators': 174, 'learning_rate': 0.32627076680608696}. Best is trial 10 with value: 0.7155000000000001.\n",
      "[I 2025-07-05 02:25:22,701] Trial 14 finished with value: 0.7144999999999999 and parameters: {'n_estimators': 174, 'learning_rate': 0.2088150000224256}. Best is trial 10 with value: 0.7155000000000001.\n",
      "[I 2025-07-05 02:25:25,153] Trial 15 finished with value: 0.7165 and parameters: {'n_estimators': 108, 'learning_rate': 0.3920625535314872}. Best is trial 15 with value: 0.7165.\n",
      "[I 2025-07-05 02:25:27,499] Trial 16 finished with value: 0.718 and parameters: {'n_estimators': 105, 'learning_rate': 0.42481767682173144}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:29,997] Trial 17 finished with value: 0.7 and parameters: {'n_estimators': 113, 'learning_rate': 0.9866038841451468}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:32,398] Trial 18 finished with value: 0.7145 and parameters: {'n_estimators': 110, 'learning_rate': 0.4383520926113583}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:34,556] Trial 19 finished with value: 0.6995 and parameters: {'n_estimators': 99, 'learning_rate': 0.7703959234307882}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:36,559] Trial 20 finished with value: 0.7150000000000001 and parameters: {'n_estimators': 92, 'learning_rate': 0.4258132602836867}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:39,192] Trial 21 finished with value: 0.712 and parameters: {'n_estimators': 120, 'learning_rate': 0.23121668217154118}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:40,339] Trial 22 finished with value: 0.7135 and parameters: {'n_estimators': 52, 'learning_rate': 0.38860945653829143}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:42,567] Trial 23 finished with value: 0.7005 and parameters: {'n_estimators': 102, 'learning_rate': 0.5955172628516525}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:46,065] Trial 24 finished with value: 0.7135 and parameters: {'n_estimators': 159, 'learning_rate': 0.25309262393240584}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:47,838] Trial 25 finished with value: 0.7130000000000001 and parameters: {'n_estimators': 81, 'learning_rate': 0.37185562597152416}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:50,517] Trial 26 finished with value: 0.694 and parameters: {'n_estimators': 122, 'learning_rate': 0.024421790775836505}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:53,949] Trial 27 finished with value: 0.7035 and parameters: {'n_estimators': 157, 'learning_rate': 0.5256130319287814}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:25:58,181] Trial 28 finished with value: 0.711 and parameters: {'n_estimators': 189, 'learning_rate': 0.16302467449869631}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:01,048] Trial 29 finished with value: 0.7005000000000001 and parameters: {'n_estimators': 131, 'learning_rate': 0.6619279693358424}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:02,581] Trial 30 finished with value: 0.709 and parameters: {'n_estimators': 70, 'learning_rate': 0.4764967264900735}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:06,672] Trial 31 finished with value: 0.7140000000000001 and parameters: {'n_estimators': 188, 'learning_rate': 0.29610702152276497}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:10,138] Trial 32 finished with value: 0.7150000000000001 and parameters: {'n_estimators': 158, 'learning_rate': 0.36369071698158456}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:14,077] Trial 33 finished with value: 0.712 and parameters: {'n_estimators': 181, 'learning_rate': 0.42315764033910847}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:16,383] Trial 34 finished with value: 0.709 and parameters: {'n_estimators': 106, 'learning_rate': 0.2678798369932703}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:18,399] Trial 35 finished with value: 0.7114999999999999 and parameters: {'n_estimators': 92, 'learning_rate': 0.49105017107278354}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:21,235] Trial 36 finished with value: 0.706 and parameters: {'n_estimators': 130, 'learning_rate': 0.5735429185370666}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:24,606] Trial 37 finished with value: 0.7135 and parameters: {'n_estimators': 151, 'learning_rate': 0.2130471960328284}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:28,344] Trial 38 finished with value: 0.7145 and parameters: {'n_estimators': 167, 'learning_rate': 0.37192932474173995}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:32,482] Trial 39 finished with value: 0.708 and parameters: {'n_estimators': 189, 'learning_rate': 0.5249310539340385}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:35,113] Trial 40 finished with value: 0.7120000000000001 and parameters: {'n_estimators': 120, 'learning_rate': 0.09679203109789525}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:39,412] Trial 41 finished with value: 0.7150000000000001 and parameters: {'n_estimators': 197, 'learning_rate': 0.3299396323837237}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:43,414] Trial 42 finished with value: 0.7154999999999999 and parameters: {'n_estimators': 182, 'learning_rate': 0.18298578598190177}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:47,396] Trial 43 finished with value: 0.7135 and parameters: {'n_estimators': 182, 'learning_rate': 0.16569594189654205}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:51,131] Trial 44 finished with value: 0.7125 and parameters: {'n_estimators': 171, 'learning_rate': 0.19334966137442594}. Best is trial 16 with value: 0.718.\n",
      "[I 2025-07-05 02:26:54,756] Trial 45 finished with value: 0.7185 and parameters: {'n_estimators': 165, 'learning_rate': 0.28974713219093584}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:26:58,440] Trial 46 finished with value: 0.7145 and parameters: {'n_estimators': 163, 'learning_rate': 0.27079026021602515}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:01,699] Trial 47 finished with value: 0.7110000000000001 and parameters: {'n_estimators': 148, 'learning_rate': 0.44140022224105613}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:04,751] Trial 48 finished with value: 0.715 and parameters: {'n_estimators': 139, 'learning_rate': 0.40406668764346926}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:06,813] Trial 49 finished with value: 0.7130000000000001 and parameters: {'n_estimators': 94, 'learning_rate': 0.33484529607501945}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:09,319] Trial 50 finished with value: 0.7144999999999999 and parameters: {'n_estimators': 114, 'learning_rate': 0.2973683523639259}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:13,247] Trial 51 finished with value: 0.71 and parameters: {'n_estimators': 179, 'learning_rate': 0.11506681692032261}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:17,132] Trial 52 finished with value: 0.717 and parameters: {'n_estimators': 176, 'learning_rate': 0.26447305352375994}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:21,412] Trial 53 finished with value: 0.716 and parameters: {'n_estimators': 194, 'learning_rate': 0.23904161479446384}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:25,630] Trial 54 finished with value: 0.7135 and parameters: {'n_estimators': 192, 'learning_rate': 0.23514711278045974}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:30,085] Trial 55 finished with value: 0.7125 and parameters: {'n_estimators': 196, 'learning_rate': 0.34918885524945303}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:34,001] Trial 56 finished with value: 0.714 and parameters: {'n_estimators': 175, 'learning_rate': 0.4617027379402695}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:38,225] Trial 57 finished with value: 0.7150000000000001 and parameters: {'n_estimators': 194, 'learning_rate': 0.28044631367651585}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:40,405] Trial 58 finished with value: 0.7165000000000001 and parameters: {'n_estimators': 100, 'learning_rate': 0.4002811769984554}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:42,647] Trial 59 finished with value: 0.7145 and parameters: {'n_estimators': 103, 'learning_rate': 0.3922551440944252}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:44,536] Trial 60 finished with value: 0.709 and parameters: {'n_estimators': 87, 'learning_rate': 0.23304128356902826}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:46,995] Trial 61 finished with value: 0.7135 and parameters: {'n_estimators': 112, 'learning_rate': 0.31097588724673175}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:51,075] Trial 62 finished with value: 0.7145 and parameters: {'n_estimators': 186, 'learning_rate': 0.45904895103788546}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:53,269] Trial 63 finished with value: 0.716 and parameters: {'n_estimators': 98, 'learning_rate': 0.4061105975098013}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:55,427] Trial 64 finished with value: 0.71 and parameters: {'n_estimators': 96, 'learning_rate': 0.5504574779156527}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:57,178] Trial 65 finished with value: 0.6945 and parameters: {'n_estimators': 74, 'learning_rate': 0.966225487080876}. Best is trial 45 with value: 0.7185.\n",
      "[I 2025-07-05 02:27:59,132] Trial 66 finished with value: 0.7200000000000001 and parameters: {'n_estimators': 86, 'learning_rate': 0.4103670333149539}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:01,663] Trial 67 finished with value: 0.7095 and parameters: {'n_estimators': 109, 'learning_rate': 0.4901219772267273}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:03,382] Trial 68 finished with value: 0.7130000000000001 and parameters: {'n_estimators': 76, 'learning_rate': 0.35353966661242126}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:04,653] Trial 69 finished with value: 0.71 and parameters: {'n_estimators': 58, 'learning_rate': 0.4250278639572502}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:06,520] Trial 70 finished with value: 0.7104999999999999 and parameters: {'n_estimators': 85, 'learning_rate': 0.25406340070354727}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:08,778] Trial 71 finished with value: 0.7135 and parameters: {'n_estimators': 103, 'learning_rate': 0.3966871153535598}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:11,378] Trial 72 finished with value: 0.7145 and parameters: {'n_estimators': 117, 'learning_rate': 0.4035659579446777}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:13,275] Trial 73 finished with value: 0.7074999999999999 and parameters: {'n_estimators': 87, 'learning_rate': 0.5109707949465276}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:15,450] Trial 74 finished with value: 0.7125000000000001 and parameters: {'n_estimators': 99, 'learning_rate': 0.3740575659172533}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:18,239] Trial 75 finished with value: 0.7144999999999999 and parameters: {'n_estimators': 128, 'learning_rate': 0.4536211995241436}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:20,576] Trial 76 finished with value: 0.712 and parameters: {'n_estimators': 107, 'learning_rate': 0.2947894343125785}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:22,703] Trial 77 finished with value: 0.696 and parameters: {'n_estimators': 97, 'learning_rate': 0.627922910622514}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:25,666] Trial 78 finished with value: 0.711 and parameters: {'n_estimators': 134, 'learning_rate': 0.3278705619135377}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:27,717] Trial 79 finished with value: 0.718 and parameters: {'n_estimators': 91, 'learning_rate': 0.41927793566530275}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:29,722] Trial 80 finished with value: 0.7074999999999999 and parameters: {'n_estimators': 89, 'learning_rate': 0.14711685431904015}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:31,749] Trial 81 finished with value: 0.7140000000000001 and parameters: {'n_estimators': 92, 'learning_rate': 0.431295843965529}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:33,223] Trial 82 finished with value: 0.7144999999999999 and parameters: {'n_estimators': 67, 'learning_rate': 0.48166780492856087}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:34,995] Trial 83 finished with value: 0.712 and parameters: {'n_estimators': 81, 'learning_rate': 0.3514737254144562}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:37,770] Trial 84 finished with value: 0.7115 and parameters: {'n_estimators': 124, 'learning_rate': 0.41291366090024023}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:40,103] Trial 85 finished with value: 0.7130000000000001 and parameters: {'n_estimators': 104, 'learning_rate': 0.5427851814792178}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:42,302] Trial 86 finished with value: 0.7150000000000001 and parameters: {'n_estimators': 100, 'learning_rate': 0.3746593586683386}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:44,846] Trial 87 finished with value: 0.7135 and parameters: {'n_estimators': 116, 'learning_rate': 0.2082022901689773}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:46,510] Trial 88 finished with value: 0.7125 and parameters: {'n_estimators': 76, 'learning_rate': 0.25197173695706454}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:48,350] Trial 89 finished with value: 0.7110000000000001 and parameters: {'n_estimators': 84, 'learning_rate': 0.3287716431967612}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:50,315] Trial 90 finished with value: 0.715 and parameters: {'n_estimators': 90, 'learning_rate': 0.4529107368992797}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:54,240] Trial 91 finished with value: 0.7164999999999999 and parameters: {'n_estimators': 178, 'learning_rate': 0.30231655297615634}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:28:58,194] Trial 92 finished with value: 0.7145 and parameters: {'n_estimators': 177, 'learning_rate': 0.3057066126621052}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:01,984] Trial 93 finished with value: 0.7130000000000001 and parameters: {'n_estimators': 172, 'learning_rate': 0.38972165661893693}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:06,025] Trial 94 finished with value: 0.712 and parameters: {'n_estimators': 185, 'learning_rate': 0.34656116078803356}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:09,661] Trial 95 finished with value: 0.7165 and parameters: {'n_estimators': 167, 'learning_rate': 0.2666038193185225}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:13,323] Trial 96 finished with value: 0.716 and parameters: {'n_estimators': 168, 'learning_rate': 0.2732888695261687}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:16,873] Trial 97 finished with value: 0.7145 and parameters: {'n_estimators': 162, 'learning_rate': 0.1988136770611788}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:20,215] Trial 98 finished with value: 0.7135 and parameters: {'n_estimators': 153, 'learning_rate': 0.24337075054609364}. Best is trial 66 with value: 0.7200000000000001.\n",
      "[I 2025-07-05 02:29:23,966] Trial 99 finished with value: 0.7154999999999999 and parameters: {'n_estimators': 168, 'learning_rate': 0.308979939513195}. Best is trial 66 with value: 0.7200000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost params: {'n_estimators': 86, 'learning_rate': 0.4103670333149539}\n",
      "Best AdaBoost cross-validation score: 0.7200\n"
     ]
    }
   ],
   "source": [
    "def optimize_adaboost(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        'algorithm': 'SAMME',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = AdaBoostClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "ada_study = optuna.create_study(direction='maximize', study_name=\"AdaBoost_optimization\")\n",
    "ada_study.optimize(optimize_adaboost, n_trials=100)\n",
    "\n",
    "print(f\"Best AdaBoost params: {ada_study.best_params}\")\n",
    "print(f\"Best AdaBoost cross-validation score: {ada_study.best_value:.4f}\")\n",
    "\n",
    "best_ada_params = ada_study.best_params\n",
    "best_ada_model = AdaBoostClassifier(**best_ada_params)\n",
    "best_ada_model.fit(X_train, y_train)\n",
    "\n",
    "best_models['AdaBoost'] = best_ada_model\n",
    "cv_results['AdaBoost'] = ada_study.best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e11fb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:29:24,451] A new study created in memory with name: SVC_optimization\n",
      "[I 2025-07-05 02:29:26,111] Trial 0 finished with value: 0.6475 and parameters: {'kernel': 'sigmoid', 'C': 0.008025045610108538, 'gamma': 0.16138916712028184}. Best is trial 0 with value: 0.6475.\n",
      "[I 2025-07-05 02:29:27,485] Trial 1 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.0005960157647714102, 'gamma': 0.1298855502502769}. Best is trial 0 with value: 0.6475.\n",
      "[I 2025-07-05 02:29:28,609] Trial 2 finished with value: 0.7444999999999999 and parameters: {'kernel': 'poly', 'C': 0.002650676766349632, 'gamma': 0.1754762515483813, 'degree': 5}. Best is trial 2 with value: 0.7444999999999999.\n",
      "[I 2025-07-05 02:29:29,295] Trial 3 finished with value: 0.753 and parameters: {'kernel': 'poly', 'C': 0.0003118014689234045, 'gamma': 0.19234693954050996, 'degree': 3}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:31,043] Trial 4 finished with value: 0.669 and parameters: {'kernel': 'sigmoid', 'C': 0.0033827258176808554, 'gamma': 0.16253591911640147}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:32,420] Trial 5 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.0008175933034864974, 'gamma': 0.17123705558444507}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:33,786] Trial 6 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.00014861829325420883, 'gamma': 0.12498384829995705}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:35,443] Trial 7 finished with value: 0.673 and parameters: {'kernel': 'sigmoid', 'C': 0.0050765807216683586, 'gamma': 0.10692433716820147}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:36,118] Trial 8 finished with value: 0.7205 and parameters: {'kernel': 'poly', 'C': 0.00016790564522832697, 'gamma': 0.15498474390394912, 'degree': 3}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:37,800] Trial 9 finished with value: 0.6725000000000001 and parameters: {'kernel': 'sigmoid', 'C': 0.004604419357878811, 'gamma': 0.11338963678500498}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:38,501] Trial 10 finished with value: 0.696 and parameters: {'kernel': 'poly', 'C': 0.00038380422121524156, 'gamma': 0.19869528303585238, 'degree': 2}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:39,605] Trial 11 finished with value: 0.743 and parameters: {'kernel': 'poly', 'C': 0.00199572325648566, 'gamma': 0.19481764464058324, 'degree': 5}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:40,702] Trial 12 finished with value: 0.7445 and parameters: {'kernel': 'poly', 'C': 0.0015459185667821625, 'gamma': 0.18097806862723823, 'degree': 5}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:41,716] Trial 13 finished with value: 0.7224999999999999 and parameters: {'kernel': 'poly', 'C': 0.0014739498277312768, 'gamma': 0.1840212303761744, 'degree': 4}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:42,379] Trial 14 finished with value: 0.7325000000000002 and parameters: {'kernel': 'poly', 'C': 0.0003009170546095372, 'gamma': 0.14339609927988953, 'degree': 3}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:43,315] Trial 15 finished with value: 0.7209999999999999 and parameters: {'kernel': 'poly', 'C': 0.0010848242292774899, 'gamma': 0.14618225724547698, 'degree': 4}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:44,024] Trial 16 finished with value: 0.683 and parameters: {'kernel': 'poly', 'C': 0.0003609291013218902, 'gamma': 0.18245687926833448, 'degree': 2}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:45,015] Trial 17 finished with value: 0.724 and parameters: {'kernel': 'poly', 'C': 0.0006125806652730846, 'gamma': 0.19914570595709982, 'degree': 4}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:45,685] Trial 18 finished with value: 0.716 and parameters: {'kernel': 'poly', 'C': 0.00010409144131745192, 'gamma': 0.17073283035357115, 'degree': 3}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:47,052] Trial 19 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.00024252699151296067, 'gamma': 0.1350431162717509}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:48,153] Trial 20 finished with value: 0.7464999999999999 and parameters: {'kernel': 'poly', 'C': 0.0013573314918220523, 'gamma': 0.1520782332886242, 'degree': 5}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:49,240] Trial 21 finished with value: 0.7450000000000001 and parameters: {'kernel': 'poly', 'C': 0.001179664410972264, 'gamma': 0.15314129395235412, 'degree': 5}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:50,319] Trial 22 finished with value: 0.743 and parameters: {'kernel': 'poly', 'C': 0.0009886733512126321, 'gamma': 0.1521734109523719, 'degree': 5}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:51,123] Trial 23 finished with value: 0.7 and parameters: {'kernel': 'poly', 'C': 0.0006107739098575514, 'gamma': 0.12039914356479145, 'degree': 4}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:52,207] Trial 24 finished with value: 0.7455 and parameters: {'kernel': 'poly', 'C': 0.0018189001959409239, 'gamma': 0.1372391881717706, 'degree': 5}. Best is trial 3 with value: 0.753.\n",
      "[I 2025-07-05 02:29:52,951] Trial 25 finished with value: 0.7714999999999999 and parameters: {'kernel': 'poly', 'C': 0.00176862252455732, 'gamma': 0.13734729341574742, 'degree': 3}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:29:53,682] Trial 26 finished with value: 0.7695 and parameters: {'kernel': 'poly', 'C': 0.0026401297098926067, 'gamma': 0.11915015166524968, 'degree': 3}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:29:54,413] Trial 27 finished with value: 0.767 and parameters: {'kernel': 'poly', 'C': 0.002596074966442534, 'gamma': 0.11635669971551069, 'degree': 3}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:29:55,843] Trial 28 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.0026688132045029496, 'gamma': 0.10316853504340824}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:29:57,487] Trial 29 finished with value: 0.6639999999999999 and parameters: {'kernel': 'sigmoid', 'C': 0.0064860944485892035, 'gamma': 0.11632790101324665}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:29:59,207] Trial 30 finished with value: 0.6759999999999999 and parameters: {'kernel': 'sigmoid', 'C': 0.003730016705211033, 'gamma': 0.11033230914751108}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:29:59,940] Trial 31 finished with value: 0.7689999999999999 and parameters: {'kernel': 'poly', 'C': 0.0023049369512615036, 'gamma': 0.12325090594314597, 'degree': 3}. Best is trial 25 with value: 0.7714999999999999.\n",
      "[I 2025-07-05 02:30:00,885] Trial 32 finished with value: 0.7765000000000001 and parameters: {'kernel': 'poly', 'C': 0.008550073565279016, 'gamma': 0.12572690731583105, 'degree': 3}. Best is trial 32 with value: 0.7765000000000001.\n",
      "[I 2025-07-05 02:30:01,518] Trial 33 finished with value: 0.7354999999999999 and parameters: {'kernel': 'poly', 'C': 0.00930899922847496, 'gamma': 0.1287266050709613, 'degree': 2}. Best is trial 32 with value: 0.7765000000000001.\n",
      "[I 2025-07-05 02:30:02,420] Trial 34 finished with value: 0.78 and parameters: {'kernel': 'poly', 'C': 0.007505050367878938, 'gamma': 0.12363062971640373, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:03,357] Trial 35 finished with value: 0.7765000000000001 and parameters: {'kernel': 'poly', 'C': 0.0074230751132430784, 'gamma': 0.1312316570349789, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:04,760] Trial 36 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.006992244646719256, 'gamma': 0.1333729449614221}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:05,740] Trial 37 finished with value: 0.773 and parameters: {'kernel': 'poly', 'C': 0.009831664206570934, 'gamma': 0.12829548904671, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:06,389] Trial 38 finished with value: 0.7355 and parameters: {'kernel': 'poly', 'C': 0.00986760056163938, 'gamma': 0.12843463004256855, 'degree': 2}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:08,034] Trial 39 finished with value: 0.6664999999999999 and parameters: {'kernel': 'sigmoid', 'C': 0.006084674977423512, 'gamma': 0.12528276685444736}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:09,446] Trial 40 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.007602077390999987, 'gamma': 0.14026156592751138}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:10,253] Trial 41 finished with value: 0.775 and parameters: {'kernel': 'poly', 'C': 0.0036288768288445486, 'gamma': 0.1319781636869047, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:11,121] Trial 42 finished with value: 0.776 and parameters: {'kernel': 'poly', 'C': 0.004926689374608452, 'gamma': 0.13119435629709086, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:11,973] Trial 43 finished with value: 0.7764999999999999 and parameters: {'kernel': 'poly', 'C': 0.004738017757228144, 'gamma': 0.1324650640715394, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:12,791] Trial 44 finished with value: 0.775 and parameters: {'kernel': 'poly', 'C': 0.004819908297097302, 'gamma': 0.12320977796900388, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:13,740] Trial 45 finished with value: 0.778 and parameters: {'kernel': 'poly', 'C': 0.005661472649390591, 'gamma': 0.14716563374214806, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:14,757] Trial 46 finished with value: 0.7245000000000001 and parameters: {'kernel': 'poly', 'C': 0.005637417146018171, 'gamma': 0.14603924143320382, 'degree': 4}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:15,691] Trial 47 finished with value: 0.7775000000000001 and parameters: {'kernel': 'poly', 'C': 0.004084957916530599, 'gamma': 0.16136603010041942, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:17,306] Trial 48 finished with value: 0.6465 and parameters: {'kernel': 'sigmoid', 'C': 0.008095210910766886, 'gamma': 0.15807080269716212}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:18,236] Trial 49 finished with value: 0.7765000000000001 and parameters: {'kernel': 'poly', 'C': 0.003967722212775026, 'gamma': 0.1624719157300166, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:18,892] Trial 50 finished with value: 0.7354999999999999 and parameters: {'kernel': 'poly', 'C': 0.007934596866129255, 'gamma': 0.1703920285945605, 'degree': 2}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:19,830] Trial 51 finished with value: 0.7765000000000001 and parameters: {'kernel': 'poly', 'C': 0.003877405200104198, 'gamma': 0.16293190997342108, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:20,987] Trial 52 finished with value: 0.776 and parameters: {'kernel': 'poly', 'C': 0.006354059711654592, 'gamma': 0.16504487311950353, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:21,823] Trial 53 finished with value: 0.7765000000000001 and parameters: {'kernel': 'poly', 'C': 0.0030589057979032394, 'gamma': 0.1478182761609161, 'degree': 3}. Best is trial 34 with value: 0.78.\n",
      "[I 2025-07-05 02:30:22,724] Trial 54 finished with value: 0.781 and parameters: {'kernel': 'poly', 'C': 0.004253297057026472, 'gamma': 0.14869220535181446, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:23,658] Trial 55 finished with value: 0.779 and parameters: {'kernel': 'poly', 'C': 0.005541516471054258, 'gamma': 0.1418135523823275, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:24,691] Trial 56 finished with value: 0.777 and parameters: {'kernel': 'poly', 'C': 0.005885849678960044, 'gamma': 0.14274295725004157, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:26,120] Trial 57 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.005495091223860185, 'gamma': 0.14127901948157018}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:26,782] Trial 58 finished with value: 0.7355 and parameters: {'kernel': 'poly', 'C': 0.00440973892698163, 'gamma': 0.156837699253751, 'degree': 2}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:27,832] Trial 59 finished with value: 0.7230000000000001 and parameters: {'kernel': 'poly', 'C': 0.003036322374271917, 'gamma': 0.1476284274023392, 'degree': 4}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:28,710] Trial 60 finished with value: 0.7764999999999999 and parameters: {'kernel': 'poly', 'C': 0.0031774886197172007, 'gamma': 0.1510823029208705, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:29,783] Trial 61 finished with value: 0.7719999999999999 and parameters: {'kernel': 'poly', 'C': 0.008637688927556876, 'gamma': 0.14338795855800318, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:30,695] Trial 62 finished with value: 0.7795 and parameters: {'kernel': 'poly', 'C': 0.005596628392135543, 'gamma': 0.13810639440603845, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:31,592] Trial 63 finished with value: 0.78 and parameters: {'kernel': 'poly', 'C': 0.005489090139149052, 'gamma': 0.1371700825866935, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:32,531] Trial 64 finished with value: 0.7779999999999999 and parameters: {'kernel': 'poly', 'C': 0.006714613559261194, 'gamma': 0.1379269505714362, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:33,526] Trial 65 finished with value: 0.7235000000000001 and parameters: {'kernel': 'poly', 'C': 0.005332575186847854, 'gamma': 0.13665572672379686, 'degree': 4}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:34,459] Trial 66 finished with value: 0.7779999999999999 and parameters: {'kernel': 'poly', 'C': 0.006754589148005682, 'gamma': 0.1376463622288397, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:36,091] Trial 67 finished with value: 0.66 and parameters: {'kernel': 'sigmoid', 'C': 0.006639191450806879, 'gamma': 0.13923791140360364}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:36,776] Trial 68 finished with value: 0.759 and parameters: {'kernel': 'poly', 'C': 0.000791431249706548, 'gamma': 0.15141923353668793, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:37,405] Trial 69 finished with value: 0.7375 and parameters: {'kernel': 'poly', 'C': 0.005421213123433983, 'gamma': 0.14531270653740536, 'degree': 2}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:38,803] Trial 70 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.004380113105611983, 'gamma': 0.1344504335889513}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:39,745] Trial 71 finished with value: 0.7785 and parameters: {'kernel': 'poly', 'C': 0.007073628141251819, 'gamma': 0.13614818733796866, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:40,775] Trial 72 finished with value: 0.7725 and parameters: {'kernel': 'poly', 'C': 0.007352491762950975, 'gamma': 0.14912857114220998, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:41,782] Trial 73 finished with value: 0.7715 and parameters: {'kernel': 'poly', 'C': 0.008690214327423031, 'gamma': 0.14025786561669626, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:42,691] Trial 74 finished with value: 0.78 and parameters: {'kernel': 'poly', 'C': 0.006129909897815652, 'gamma': 0.13552837656681588, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:43,565] Trial 75 finished with value: 0.781 and parameters: {'kernel': 'poly', 'C': 0.005086557692880705, 'gamma': 0.13513712817220788, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:44,546] Trial 76 finished with value: 0.723 and parameters: {'kernel': 'poly', 'C': 0.0035632168279677674, 'gamma': 0.13447833151895072, 'degree': 4}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:45,258] Trial 77 finished with value: 0.7675 and parameters: {'kernel': 'poly', 'C': 0.002292327321630457, 'gamma': 0.11995486680656299, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:46,084] Trial 78 finished with value: 0.7769999999999999 and parameters: {'kernel': 'poly', 'C': 0.0046504423008597185, 'gamma': 0.12971861423735992, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:46,889] Trial 79 finished with value: 0.7735000000000001 and parameters: {'kernel': 'poly', 'C': 0.004284903768235671, 'gamma': 0.12697828830882651, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:48,526] Trial 80 finished with value: 0.6664999999999999 and parameters: {'kernel': 'sigmoid', 'C': 0.0062325693841088214, 'gamma': 0.12237116155634258}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:49,428] Trial 81 finished with value: 0.7805 and parameters: {'kernel': 'poly', 'C': 0.005069555339507766, 'gamma': 0.14184965541902245, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:50,326] Trial 82 finished with value: 0.7795 and parameters: {'kernel': 'poly', 'C': 0.0049833761089864426, 'gamma': 0.14360245472872124, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:51,238] Trial 83 finished with value: 0.7805 and parameters: {'kernel': 'poly', 'C': 0.00510841886017278, 'gamma': 0.14287872894545206, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:52,072] Trial 84 finished with value: 0.7769999999999999 and parameters: {'kernel': 'poly', 'C': 0.0033930014402580072, 'gamma': 0.14392390768073512, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:53,032] Trial 85 finished with value: 0.7775000000000001 and parameters: {'kernel': 'poly', 'C': 0.004960880018035342, 'gamma': 0.1556708854633943, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:53,968] Trial 86 finished with value: 0.7775000000000001 and parameters: {'kernel': 'poly', 'C': 0.005139584066518993, 'gamma': 0.14962794565677817, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:54,633] Trial 87 finished with value: 0.7210000000000001 and parameters: {'kernel': 'poly', 'C': 0.0005001787047086225, 'gamma': 0.11026562833144966, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:56,030] Trial 88 finished with value: 0.5095 and parameters: {'kernel': 'rbf', 'C': 0.0028538110745914675, 'gamma': 0.1539541925790212}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:57,013] Trial 89 finished with value: 0.7699999999999999 and parameters: {'kernel': 'poly', 'C': 0.007640566898757909, 'gamma': 0.1448385498202831, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:57,844] Trial 90 finished with value: 0.7769999999999999 and parameters: {'kernel': 'poly', 'C': 0.0038686655830388384, 'gamma': 0.13929604493198888, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:58,770] Trial 91 finished with value: 0.7765000000000001 and parameters: {'kernel': 'poly', 'C': 0.0058318175627899305, 'gamma': 0.1427357702495127, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:30:59,609] Trial 92 finished with value: 0.7765 and parameters: {'kernel': 'poly', 'C': 0.004426764962451452, 'gamma': 0.13320638238445145, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:00,537] Trial 93 finished with value: 0.777 and parameters: {'kernel': 'poly', 'C': 0.006094946961384484, 'gamma': 0.14113132781856064, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:01,403] Trial 94 finished with value: 0.781 and parameters: {'kernel': 'poly', 'C': 0.005114065980361234, 'gamma': 0.13540384681627038, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:02,251] Trial 95 finished with value: 0.7774999999999999 and parameters: {'kernel': 'poly', 'C': 0.005084538642600563, 'gamma': 0.13059272856102128, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:03,227] Trial 96 finished with value: 0.773 and parameters: {'kernel': 'poly', 'C': 0.008986800173433798, 'gamma': 0.134973131112315, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:04,071] Trial 97 finished with value: 0.776 and parameters: {'kernel': 'poly', 'C': 0.004149757345894931, 'gamma': 0.1389704394375646, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:04,741] Trial 98 finished with value: 0.7135 and parameters: {'kernel': 'poly', 'C': 0.00023006495128207727, 'gamma': 0.126419264771374, 'degree': 3}. Best is trial 54 with value: 0.781.\n",
      "[I 2025-07-05 02:31:06,447] Trial 99 finished with value: 0.6784999999999999 and parameters: {'kernel': 'sigmoid', 'C': 0.0035398847630281165, 'gamma': 0.10071995528539159}. Best is trial 54 with value: 0.781.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC params: {'kernel': 'poly', 'C': 0.004253297057026472, 'gamma': 0.14869220535181446, 'degree': 3}\n",
      "Best SVC cross-validation score: 0.7810\n"
     ]
    }
   ],
   "source": [
    "def optimize_svc(trial):\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-4, 1e-2, log=True),\n",
    "        'kernel': kernel,\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 0.2, log=True),\n",
    "        'degree': trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3,\n",
    "        'probability': True,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = SVC(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "svc_study = optuna.create_study(direction='maximize', study_name=\"SVC_optimization\")\n",
    "svc_study.optimize(optimize_svc, n_trials=100)\n",
    "\n",
    "print(f\"Best SVC params: {svc_study.best_params}\")\n",
    "print(f\"Best SVC cross-validation score: {svc_study.best_value:.4f}\")\n",
    "\n",
    "best_svc_params = svc_study.best_params\n",
    "best_svc_model = SVC(**best_svc_params)\n",
    "best_svc_model.fit(X_train, y_train)\n",
    "\n",
    "best_models['SVC'] = best_svc_model\n",
    "cv_results['SVC'] = svc_study.best_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec52a3",
   "metadata": {},
   "source": [
    "## Model validation on test data\n",
    "\n",
    "We finally validate on the test data and verify if the mean accuracy is better than 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f6036d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression       | CV Score: 0.7230\n",
      "K-Nearest Neighbors       | CV Score: 0.7860\n",
      "MLP Classifier            | CV Score: 0.7565\n",
      "AdaBoost                  | CV Score: 0.7200\n",
      "SVC                       | CV Score: 0.7810\n",
      "\n",
      "Evaluating models on test set (Target: 0.85):\n",
      "--------------------------------------------------\n",
      "Logistic Regression       | Test Accuracy: 0.7465 \n",
      "K-Nearest Neighbors       | Test Accuracy: 0.7925 \n",
      "MLP Classifier            | Test Accuracy: 0.7600 \n",
      "AdaBoost                  | Test Accuracy: 0.7420 \n",
      "SVC                       | Test Accuracy: 0.9040 \n",
      "\n",
      "Models achieving target accuracy (0.85) on TEST SET:\n",
      "SVC: 0.9040\n",
      "\n",
      "Best test performer: SVC\n",
      "Best test accuracy: 0.9040\n"
     ]
    }
   ],
   "source": [
    "for name, score in cv_results.items():\n",
    "    print(f\"{name:25s} | CV Score: {score:.4f}\")\n",
    "\n",
    "test_accuracies = {}\n",
    "print(f\"\\nEvaluating models on test set (Target: {TARGET_ACCURACY}):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies[name] = test_acc\n",
    "    \n",
    "    status = \"\" if test_acc > TARGET_ACCURACY else \"\"\n",
    "    print(f\"{name:25s} | Test Accuracy: {test_acc:.4f} {status}\")\n",
    "\n",
    "models_above_target = [name for name, score in test_accuracies.items() if score > TARGET_ACCURACY]\n",
    "print(f\"\\nModels achieving target accuracy ({TARGET_ACCURACY}) on TEST SET:\")\n",
    "if models_above_target:\n",
    "    for model in models_above_target:\n",
    "        print(f\"{model}: {test_accuracies[model]:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nBest test performer: {max(test_accuracies.keys(), key=lambda x: test_accuracies[x])}\")\n",
    "print(f\"Best test accuracy: {max(test_accuracies.values()):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396dd9a8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We see that SVC performed really well. It got a mean accuracy of 0.9040. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
